{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import tqdm\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token = '#PAD_TOKEN'\n",
    "type_to_ix = {'person': 0, 'user': 1, 'song': 2, pad_token: 3}\n",
    "relation_to_ix = {'song_person': 0, 'person_song': 1, 'user_song': \n",
    "                  2, 'song_user': 3, '#UNK_RELATION': 4, '#END_RELATION': 5, pad_token: 6}\n",
    "\n",
    "PERSON_TYPE = 0\n",
    "USER_TYPE = 1\n",
    "SONG_TYPE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct mappings from entity, type, and relation to idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entity vocab set is combination of songs, users, and persons\n",
    "#currently using dicts and not id_txt files since it seemed like there were missing songs\n",
    "with open('../song_data/dense_song_user_edges.dict', 'rb') as handle:\n",
    "    songs1 = set(pickle.load(handle).keys())\n",
    "    \n",
    "with open('../song_data/dense_song_person_edges.dict', 'rb') as handle:\n",
    "    songs2 = set(pickle.load(handle).keys())\n",
    "\n",
    "with open('../song_data/dense_user_song_edges.dict', 'rb') as handle:\n",
    "    users = set(pickle.load(handle).keys())\n",
    "    \n",
    "with open('../song_data/dense_person_song_edges.dict', 'rb') as handle:\n",
    "    persons = set(pickle.load(handle).keys())\n",
    "\n",
    "songs = songs1|songs2\n",
    "entities = songs|users|persons\n",
    "\n",
    "#if we have singe map for all entities need to ensure no duplicates across categories\n",
    "#assert len(entities) == len(songs) + len(persons) + len(users)\n",
    "\n",
    "song_to_ix = {(song, SONG_TYPE): idx for idx, song in enumerate(songs)}\n",
    "user_to_ix = {(user, USER_TYPE): idx+len(song_to_ix) for idx, user in enumerate(users)}\n",
    "person_to_ix = {(person, PERSON_TYPE): idx+len(song_to_ix)+len(user_to_ix) for idx, person in enumerate(persons)}\n",
    "\n",
    "entity_to_ix = {(song, SONG_TYPE): idx for idx, song in enumerate(songs)}\n",
    "entity_to_ix.update({(user, USER_TYPE): idx+len(song_to_ix) for idx, user in enumerate(users)})\n",
    "entity_to_ix.update({(person, PERSON_TYPE): idx+len(song_to_ix)+len(user_to_ix) for idx, person in enumerate(persons)})\n",
    "# entity_to_ix = {entity: idx for idx, entity in enumerate(entities)}\n",
    "entity_to_ix[pad_token] = len(entity_to_ix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(song_to_ix.items())[:10])\n",
    "print(list(user_to_ix.items())[:10])\n",
    "print(list(person_to_ix.items())[:10])\n",
    "print(len(entity_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(songs) + len(persons) + len(users))\n",
    "print(len(entity_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in entities)\n",
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in persons)\n",
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in users)\n",
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct inverse idx mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_type = {v: k for k, v in type_to_ix.items()}\n",
    "ix_to_relation = {v: k for k, v in relation_to_ix.items()}\n",
    "ix_to_entity = {v: k for k, v in entity_to_ix.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save idx mappings as .dict files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('type_to_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(type_to_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('relation_to_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(relation_to_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('entity_to_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(entity_to_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('ix_to_type.dict', 'wb') as handle:\n",
    "    pickle.dump(ix_to_type, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('ix_to_relation.dict', 'wb') as handle:\n",
    "    pickle.dump(ix_to_relation, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('ix_to_entity.dict', 'wb') as handle:\n",
    "    pickle.dump(ix_to_entity, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Construct relation and type dictionaries replacing names with ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ids(rel_dict, start_type, end_type):\n",
    "    new_rel = {}\n",
    "    for key,values in rel_dict.items():\n",
    "        key_id = entity_to_ix[(key, start_type)]\n",
    "        value_ids = []\n",
    "        for val in values:\n",
    "            value_ids.append(entity_to_ix[(val, end_type)])\n",
    "        new_rel[key_id] = value_ids\n",
    "    \n",
    "    return new_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)\n",
    "with open('../song_data/dense_song_user_edges.dict', 'rb') as handle:\n",
    "    song_user = pickle.load(handle)\n",
    "    song_user_ix = convert_to_ids(song_user, SONG_TYPE, USER_TYPE)\n",
    "\n",
    "print(1)\n",
    "with open('../song_data/dense_user_song_edges.dict', 'rb') as handle:\n",
    "    user_song = pickle.load(handle)\n",
    "    user_song_ix = convert_to_ids(user_song, USER_TYPE, SONG_TYPE)\n",
    "\n",
    "print(1)\n",
    "with open('../song_data/dense_song_person_edges.dict', 'rb') as handle:\n",
    "    song_person = pickle.load(handle)\n",
    "    song_person_ix = convert_to_ids(song_person, SONG_TYPE, PERSON_TYPE)\n",
    "\n",
    "print(1)\n",
    "with open('../song_data/dense_person_song_edges.dict', 'rb') as handle:\n",
    "    person_song = pickle.load(handle)\n",
    "    person_song_ix = convert_to_ids(person_song, PERSON_TYPE, SONG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert entity to id dict to entity_ix to id dict\n",
    "with open('../song_data/id_type.dict', 'rb') as handle:\n",
    "    entity_type = pickle.load(handle)\n",
    "    entity_ix_type = {}\n",
    "    for key in entities:\n",
    "        value = entity_type[key]\n",
    "        key_id = entity_to_ix[(key, int(value))]    \n",
    "        entity_ix_type[key_id] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('song_user_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(song_user_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(user_song_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('song_person_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(song_person_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('person_song_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(person_song_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('entity_ix_type.dict', 'wb') as handle:\n",
    "    pickle.dump(entity_ix_type, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert training test pos neg dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../song_data/song_user_train_dense.dict', 'rb') as handle:\n",
    "    song_user_train = pickle.load(handle)\n",
    "    song_user_train_ix = convert_to_ids(song_user_train, SONG_TYPE, USER_TYPE)\n",
    "with open('../song_data/song_user_test_dense.dict', 'rb') as handle:\n",
    "    song_user_test = pickle.load(handle)\n",
    "    song_user_test_ix = convert_to_ids(song_user_test, SONG_TYPE, USER_TYPE)\n",
    "with open('../song_data/user_song_train_dense.dict', 'rb') as handle:\n",
    "    user_song_train = pickle.load(handle)\n",
    "    user_song_train_ix = convert_to_ids(user_song, USER_TYPE, SONG_TYPE)\n",
    "with open('../song_data/user_song_test_dense.dict', 'rb') as handle:\n",
    "    user_song_test = pickle.load(handle)\n",
    "    user_song_test_ix = convert_to_ids(user_song_test, USER_TYPE, SONG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('song_user_train_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(song_user_train_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('song_user_test_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(song_user_test_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_train_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(user_song_train_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_test_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(user_song_test_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ids_tuples(tuples, start_type, end_type):\n",
    "    new_tuples = []\n",
    "    for user,song in tuples:\n",
    "        user_id = entity_to_ix[(user, start_type)]\n",
    "        song_id = entity_to_ix[(song, end_type)]\n",
    "        new_tuples.append((user_id, song_id))\n",
    "        \n",
    "    return new_tuples\n",
    "\n",
    "with open('../song_data/user_song_tuple_train_pos_dense.txt', 'rb') as handle:\n",
    "    user_song_tuple_train_pos = pickle.load(handle)\n",
    "    user_song_tuple_train_pos_ix = convert_to_ids_tuples(user_song_tuple_train_pos, USER_TYPE, SONG_TYPE)\n",
    "with open('../song_data/user_song_tuple_test_pos_dense.txt', 'rb') as handle:\n",
    "    user_song_tuple_test_pos = pickle.load(handle)\n",
    "    user_song_tuple_test_pos_ix = convert_to_ids_tuples(user_song_tuple_test_pos, USER_TYPE, SONG_TYPE)\n",
    "with open('../song_data/user_song_tuple_train_neg_dense.txt', 'rb') as handle:\n",
    "    user_song_tuple_train_neg = pickle.load(handle)\n",
    "    user_song_tuple_train_neg_ix = convert_to_ids_tuples(user_song_tuple_train_neg, USER_TYPE, SONG_TYPE)\n",
    "with open('../song_data/user_song_tuple_test_neg_dense.txt', 'rb') as handle:\n",
    "    user_song_tuple_test_neg = pickle.load(handle)\n",
    "    user_song_tuple_test_neg_ix = convert_to_ids_tuples(user_song_tuple_test_neg, USER_TYPE, SONG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('user_song_tuple_train_pos_ix.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple_train_pos_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_tuple_train_neg_ix.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple_train_neg_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_tuple_test_pos_ix.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple_test_pos_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_tuple_test_neg_ix.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple_test_neg_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
