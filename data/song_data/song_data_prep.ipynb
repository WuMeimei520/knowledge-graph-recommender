{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv(\"songs.csv\")\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_type_idx = 0\n",
    "user_type_idx = 1\n",
    "song_type_idx = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize into dict & arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# song_person.dict & person_song.dict\n",
    "# dict where key = song_id, value = list of persons (artists, composers, lyricists) of the song\n",
    "def make_person_list(row):\n",
    "    person_set = set()\n",
    "    if not isinstance(row['artist_name'], float):\n",
    "        for x in row['artist_name'].split('|'):\n",
    "            person_set.add(x.strip())\n",
    "    if not isinstance(row['composer'], float):\n",
    "        for x in row['composer'].split('|'):\n",
    "            person_set.add(x.strip())\n",
    "    if not isinstance(row['lyricist'], float):\n",
    "        for x in row['lyricist'].split('|'):\n",
    "            person_set.add(x.strip())\n",
    "    return list(person_set)\n",
    "\n",
    "person = songs[['song_id','artist_name', 'composer', 'lyricist']]\n",
    "person_list = person.apply(lambda x: make_person_list(x), axis=1)\n",
    "song_person = pd.concat([songs['song_id'], person_list], axis=1)\n",
    "song_person.columns=['song_id', 'person_list']\n",
    "song_person_dict = song_person.set_index('song_id')['person_list'].to_dict()\n",
    "with open('song_person.dict', 'wb') as handle:\n",
    "    pickle.dump(song_person_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# dict where key = a person, value = list of songs related to this person\n",
    "person_song_dict = {}\n",
    "for row in song_person.iterrows():\n",
    "     for person in row[1]['person_list']:\n",
    "            if person not in person_song_dict:\n",
    "                person_song_dict[person]=[]\n",
    "            person_song_dict[person].append(row[1]['song_id'])\n",
    "with open('person_song.dict', 'wb') as handle:\n",
    "    pickle.dump(person_song_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_type.dict\n",
    "#dict where key = entity id, value = entity type\n",
    "#person_id: the set of artist_name, composer, lyricist of all songs\n",
    "#type index: person = 0, user = 1, song = 2\n",
    "song_id_songs = songs['song_id'].drop_duplicates().values #numpy.ndarray\n",
    "song_id_train = train['song_id'].drop_duplicates().values #numpy.ndarray\n",
    "song_id = np.hstack([song_id_songs, song_id_train])\n",
    "song_id = np.unique(song_id)\n",
    "song_id = np.expand_dims(song_id, axis=1)\n",
    "song_type = np.full(song_id.shape, song_type_idx, dtype=int)\n",
    "song_id_type = np.concatenate((song_id, song_type), axis=1)\n",
    "\n",
    "user_id = train['msno'].drop_duplicates().values #numpy.ndarray\n",
    "user_id = np.expand_dims(user_id, axis=1)\n",
    "user_type = np.full(user_id.shape, user_type_idx, dtype=int)\n",
    "user_id_type = np.concatenate((user_id, user_type), axis=1)\n",
    "\n",
    "person_list = songs[['artist_name', 'composer', 'lyricist']].stack(dropna=True).drop_duplicates().to_numpy()\n",
    "person_set = set()\n",
    "for pseudo_person in person_list:\n",
    "    for person in pseudo_person.split('|'):\n",
    "        person_set.add(person.strip())\n",
    "person_arr = np.array(list(person_set))\n",
    "person_id = np.expand_dims(person_arr, axis=1)\n",
    "person_type = np.full(person_id.shape, person_type_idx, dtype=int)\n",
    "person_id_type = np.concatenate((person_id, person_type), axis=1)\n",
    "\n",
    "id_type_ndarray = np.concatenate((song_id_type, user_id_type, person_id_type), axis=0)\n",
    "\n",
    "id_type = {entity_id : entity_type for entity_id, entity_type in id_type_ndarray}\n",
    "with open('id_type.dict', 'wb') as handle:\n",
    "    pickle.dump(id_type, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in id_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# person_id.txt\n",
    "# numpy array of sorted unique person_ids\n",
    "person_arr.sort()\n",
    "with open('person_id.txt', 'wb') as handle:\n",
    "    pickle.dump(person_id, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# song_user.dict\n",
    "# dict where key = song_id, value = list of user_ids\n",
    "song_user = train[['song_id', 'msno']].set_index('song_id').groupby('song_id')['msno'].apply(list).to_dict()\n",
    "# msno is the user_id\n",
    "with open('song_user.dict', 'wb') as handle:\n",
    "    pickle.dump(song_user, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_song.dict\n",
    "# dict where key = user_id, value = list of song_ids\n",
    "user_song = train[['msno', 'song_id']].set_index('msno').groupby('msno')['song_id'].apply(list).to_dict()\n",
    "with open('user_song.dict', 'wb') as handle:\n",
    "    pickle.dump(user_song, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# song_id.txt\n",
    "# numpy array of sorted unique song_ids\n",
    "song_id = songs['song_id'].drop_duplicates().values\n",
    "song_id.sort()\n",
    "with open('song_id.txt', 'wb') as handle:\n",
    "    pickle.dump(song_id, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id.txt\n",
    "# numpy array of sorted unique user_ids\n",
    "user_id = train['msno'].sort_values().drop_duplicates().values\n",
    "with open('user_id.txt', 'wb') as handle:\n",
    "    pickle.dump(user_id, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_song_tuple.txt\n",
    "# numpy array of [user_id, song_id] pairs sorted in the order of user_id\n",
    "user_song_tuple = train[['msno', 'song_id']].sort_values(by='msno').to_string(header=False, index=False, index_names=False).split('\\n')\n",
    "# user_song_tuple = '\\n'.join(['\\t'.join(row.split()) for row in user_song_tuple]) \n",
    "user_song_tuple = [row.split() for row in user_song_tuple]\n",
    "with open('user_song_tuple.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deserialize checks (preview of output format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('song_person.dict', 'rb') as handle:\n",
    "    unserialized_song_person = pickle.load(handle)\n",
    "{k: v for k, v in unserialized_song_person.items() if len(v) >1} # to show that the list is working\n",
    "\n",
    "with open('person_song.dict', 'rb') as handle:\n",
    "    unserialized_person_song = pickle.load(handle)\n",
    "{k: v for k, v in unserialized_person_song.items() if len(v) >1} # to show that the list is working\n",
    "\n",
    "with open('id_type.dict', 'rb') as handle:\n",
    "    unserialized_id_type = pickle.load(handle)\n",
    "dict(itertools.islice(unserialized_id_type.items(), 3))\n",
    "\n",
    "with open('song_user.dict', 'rb') as handle:\n",
    "    unserialized_song_user = pickle.load(handle)\n",
    "unserialized_song_user['BBzumQNXUHKdEBOB7mAJuzok+IJA1c2Ryg/yzTF6tik='] # one instance\n",
    "{k: v for k, v in unserialized_song_user.items() if len(v) >1} # to show that the list is working\n",
    "\n",
    "with open('song_id.txt', 'rb') as handle:\n",
    "    unserialized_song_id = pickle.load(handle)\n",
    "unserialized_song_id[:5]\n",
    "\n",
    "with open('user_song_tuple.txt', 'rb') as handle:\n",
    "    unserialized_user_song_tuple = pickle.load(handle)\n",
    "unserialized_user_song_tuple[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
