{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import tqdm\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import sys\n",
    "from os import path\n",
    "sys.path.append(path.dirname(path.dirname(path.abspath('../constants'))))\n",
    "import constants.consts as consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad_token = consts.PAD_TOKEN\n",
    "type_to_ix = {'person': consts.PERSON_TYPE, 'user': consts.USER_TYPE, 'song': consts.SONG_TYPE, \n",
    "              pad_token: consts.PAD_TYPE}\n",
    "relation_to_ix = {'song_person': consts.SONG_PERSON_REL, 'person_song': consts.PERSON_SONG_REL, 'user_song': \n",
    "                  consts.USER_SONG_REL, 'song_user': consts.SONG_USER_REL, '#UNK_RELATION': consts.UNK_REL, \n",
    "                  '#END_RELATION': consts.END_REL, pad_token: consts.PAD_REL}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct mappings from entity, type, and relation to idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#entity vocab set is combination of songs, users, and persons\n",
    "#currently using dicts and not id_txt files since it seemed like there were missing songs\n",
    "with open('../song_data/dense_song_user_edges.dict', 'rb') as handle:\n",
    "    songs1 = set(pickle.load(handle).keys())\n",
    "    \n",
    "with open('../song_data/dense_song_person_edges.dict', 'rb') as handle:\n",
    "    songs2 = set(pickle.load(handle).keys())\n",
    "\n",
    "with open('../song_data/dense_user_song_edges.dict', 'rb') as handle:\n",
    "    users = set(pickle.load(handle).keys())\n",
    "    \n",
    "with open('../song_data/dense_person_song_edges.dict', 'rb') as handle:\n",
    "    persons = set(pickle.load(handle).keys())\n",
    "\n",
    "songs = songs1|songs2\n",
    "entities = songs|users|persons\n",
    "\n",
    "#if we have singe map for all entities need to ensure no duplicates across categories\n",
    "#assert len(entities) == len(songs) + len(persons) + len(users)\n",
    "\n",
    "song_to_ix = {(song, consts.SONG_TYPE): idx for idx, song in enumerate(songs)}\n",
    "user_to_ix = {(user, consts.USER_TYPE): idx+len(song_to_ix) for idx, user in enumerate(users)}\n",
    "person_to_ix = {(person, consts.PERSON_TYPE): idx+len(song_to_ix)+len(user_to_ix) for idx, person in enumerate(persons)}\n",
    "\n",
    "entity_to_ix = {(song, consts.SONG_TYPE): idx for idx, song in enumerate(songs)}\n",
    "entity_to_ix.update({(user, consts.USER_TYPE): idx+len(song_to_ix) for idx, user in enumerate(users)})\n",
    "entity_to_ix.update({(person, consts.PERSON_TYPE): idx+len(song_to_ix)+len(user_to_ix) for idx, person in enumerate(persons)})\n",
    "# entity_to_ix = {entity: idx for idx, entity in enumerate(entities)}\n",
    "entity_to_ix[pad_token] = len(entity_to_ix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('9g01XAsID4VdZkPzjGQ+m9ukp9KZlKCzUZbHdvBIK/M=', 2), 0), (('DHV6UsyY/SaG9sQJSMX8wp88lrzgtE/YZNqTljmVHxs=', 2), 1), (('Fb8+EVTFkAVdR7XZO3szbDMWodYnmCw/CVOajQ4nUk0=', 2), 2), (('v38wgNSD4Da1Ha4fnbRDbxf0K4GP0By5z7iMi8gWUg0=', 2), 3), (('2cm7JlohWjfq9ASqD76I3GPzguAXXPFJj7sHJtKUIbc=', 2), 4), (('OiY3sRquCoAuZzdtxLvnIdE8+Uz2vetQIx8z/stGRkA=', 2), 5), (('iuydOcKLh7ee7hL6+WEqc+XJ0TL08y/ft0HsDOP7Tv0=', 2), 6), (('VbEEN71Ph6HiY3k9hXXiVH4sBHv2SLaUl18P7Yyq/fg=', 2), 7), (('NsXl1RDjES8dOOu5LInbB/xoWI3bNhzYCYyRM5iJeg0=', 2), 8), (('hunillniveXl9KpspTBJibHG3N2tqxpmMlu5GY6+DkU=', 2), 9)]\n",
      "[(('hLW9bmvBcywLyucaDKDZlKXvHDmC0UWtdd4jHwY37OU=', 1), 224214), (('YMQmW0gyc1CYR1aLrw4vAomobw3ZYHW8N2Sed+w+15k=', 1), 224215), (('NGBFuLGTCYZyIikX2bKpI2Z+zO7ILujTyuF5YUOqFzQ=', 1), 224216), (('k6RlVKRSRiifGsD+57TN2JeDvcbztXhgx8Uko6764t8=', 1), 224217), (('c1jkesN7viQZmVxXt8mBv7bMGiasmKupwVWK4B9JPSY=', 1), 224218), (('KXS4mDTuweetiTTxgkbg8uohB20KUXvkXz6g4l3r40c=', 1), 224219), (('pEpFpxyq3HMPhnigrVONiQjDODv55gG1AfvBQIzwNGg=', 1), 224220), (('YkeCU3BTpdMuL/MpH5V/Gl8C83J6/7dTEwBrG3bR6uk=', 1), 224221), (('112s6XK6YJqrOGJF+YrEiXwtQFK2Z7ZKBtedSQk/Bqs=', 1), 224222), (('FGqBebsinq4fszaFAyN4WqDL6vnhMlMe248eN5EgnWI=', 1), 224223)]\n",
      "[(('', 0), 227330), (('Jerry Salley', 0), 227331), (('Anthony Kavanagh', 0), 227332), (('李世光', 0), 227333), (('一休', 0), 227334), (('Sandro Silva', 0), 227335), (('Brent Michael Kutzle', 0), 227336), (('家家 (JiaJia)', 0), 227337), (('Marc-Antoine Charpentier', 0), 227338), (('Foster', 0), 227339)]\n",
      "262654\n"
     ]
    }
   ],
   "source": [
    "print(list(song_to_ix.items())[:10])\n",
    "print(list(user_to_ix.items())[:10])\n",
    "print(list(person_to_ix.items())[:10])\n",
    "print(len(entity_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262653\n",
      "262654\n"
     ]
    }
   ],
   "source": [
    "print(len(songs) + len(persons) + len(users))\n",
    "print(len(entity_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in entities)\n",
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in persons)\n",
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in users)\n",
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct inverse idx mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ix_to_type = {v: k for k, v in type_to_ix.items()}\n",
    "ix_to_relation = {v: k for k, v in relation_to_ix.items()}\n",
    "ix_to_entity = {v: k for k, v in entity_to_ix.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save idx mappings as .dict files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('type_to_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(type_to_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('relation_to_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(relation_to_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('entity_to_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(entity_to_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('ix_to_type.dict', 'wb') as handle:\n",
    "    pickle.dump(ix_to_type, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('ix_to_relation.dict', 'wb') as handle:\n",
    "    pickle.dump(ix_to_relation, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('ix_to_entity.dict', 'wb') as handle:\n",
    "    pickle.dump(ix_to_entity, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Construct relation and type dictionaries replacing names with ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_ids(rel_dict, start_type, end_type):\n",
    "    new_rel = {}\n",
    "    for key,values in rel_dict.items():\n",
    "        key_id = entity_to_ix[(key, start_type)]\n",
    "        value_ids = []\n",
    "        for val in values:\n",
    "            value_ids.append(entity_to_ix[(val, end_type)])\n",
    "        new_rel[key_id] = value_ids\n",
    "    \n",
    "    return new_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)\n",
    "with open('../song_data/dense_song_user_edges.dict', 'rb') as handle:\n",
    "    song_user = pickle.load(handle)\n",
    "    song_user_ix = convert_to_ids(song_user, consts.SONG_TYPE, consts.USER_TYPE)\n",
    "\n",
    "print(1)\n",
    "with open('../song_data/dense_user_song_edges.dict', 'rb') as handle:\n",
    "    user_song = pickle.load(handle)\n",
    "    user_song_ix = convert_to_ids(user_song, consts.USER_TYPE, consts.SONG_TYPE)\n",
    "\n",
    "print(1)\n",
    "with open('../song_data/dense_song_person_edges.dict', 'rb') as handle:\n",
    "    song_person = pickle.load(handle)\n",
    "    song_person_ix = convert_to_ids(song_person, consts.SONG_TYPE, consts.PERSON_TYPE)\n",
    "\n",
    "print(1)\n",
    "with open('../song_data/dense_person_song_edges.dict', 'rb') as handle:\n",
    "    person_song = pickle.load(handle)\n",
    "    person_song_ix = convert_to_ids(person_song, consts.PERSON_TYPE, consts.SONG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert entity to id dict to entity_ix to id dict\n",
    "with open('../song_data/id_type.dict', 'rb') as handle:\n",
    "    entity_type = pickle.load(handle)\n",
    "    entity_ix_type = {}\n",
    "    for key in entities:\n",
    "        value = entity_type[key]\n",
    "        key_id = entity_to_ix[(key, int(value))]    \n",
    "        entity_ix_type[key_id] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('song_user_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(song_user_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(user_song_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('song_person_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(song_person_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('person_song_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(person_song_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('entity_ix_type.dict', 'wb') as handle:\n",
    "    pickle.dump(entity_ix_type, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert training test pos neg dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../song_data/song_user_train_dense.dict', 'rb') as handle:\n",
    "    song_user_train = pickle.load(handle)\n",
    "    song_user_train_ix = convert_to_ids(song_user_train, consts.SONG_TYPE, consts.USER_TYPE)\n",
    "with open('../song_data/song_user_test_dense.dict', 'rb') as handle:\n",
    "    song_user_test = pickle.load(handle)\n",
    "    song_user_test_ix = convert_to_ids(song_user_test, consts.SONG_TYPE, consts.USER_TYPE)\n",
    "with open('../song_data/user_song_train_dense.dict', 'rb') as handle:\n",
    "    user_song_train = pickle.load(handle)\n",
    "    user_song_train_ix = convert_to_ids(user_song, consts.USER_TYPE, consts.SONG_TYPE)\n",
    "with open('../song_data/user_song_test_dense.dict', 'rb') as handle:\n",
    "    user_song_test = pickle.load(handle)\n",
    "    user_song_test_ix = convert_to_ids(user_song_test, consts.USER_TYPE, consts.SONG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('song_user_train_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(song_user_train_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('song_user_test_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(song_user_test_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_train_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(user_song_train_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_test_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(user_song_test_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_ids_tuples(tuples, start_type, end_type):\n",
    "    new_tuples = []\n",
    "    for user,song in tuples:\n",
    "        user_id = entity_to_ix[(user, start_type)]\n",
    "        song_id = entity_to_ix[(song, end_type)]\n",
    "        new_tuples.append((user_id, song_id))\n",
    "        \n",
    "    return new_tuples\n",
    "\n",
    "with open('../song_data/user_song_tuple_train_pos_dense.txt', 'rb') as handle:\n",
    "    user_song_tuple_train_pos = pickle.load(handle)\n",
    "    user_song_tuple_train_pos_ix = convert_to_ids_tuples(user_song_tuple_train_pos, consts.USER_TYPE, consts.SONG_TYPE)\n",
    "with open('../song_data/user_song_tuple_test_pos_dense.txt', 'rb') as handle:\n",
    "    user_song_tuple_test_pos = pickle.load(handle)\n",
    "    user_song_tuple_test_pos_ix = convert_to_ids_tuples(user_song_tuple_test_pos, consts.USER_TYPE, consts.SONG_TYPE)\n",
    "with open('../song_data/user_song_tuple_train_neg_dense.txt', 'rb') as handle:\n",
    "    user_song_tuple_train_neg = pickle.load(handle)\n",
    "    user_song_tuple_train_neg_ix = convert_to_ids_tuples(user_song_tuple_train_neg, consts.USER_TYPE, consts.SONG_TYPE)\n",
    "with open('../song_data/user_song_tuple_test_neg_dense.txt', 'rb') as handle:\n",
    "    user_song_tuple_test_neg = pickle.load(handle)\n",
    "    user_song_tuple_test_neg_ix = convert_to_ids_tuples(user_song_tuple_test_neg, consts.USER_TYPE, consts.SONG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('user_song_tuple_train_pos_ix.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple_train_pos_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_tuple_train_neg_ix.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple_train_neg_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_tuple_test_pos_ix.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple_test_pos_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_tuple_test_neg_ix.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple_test_neg_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
