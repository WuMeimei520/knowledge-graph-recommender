{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import tqdm\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token = '#PAD_TOKEN'\n",
    "type_to_ix = {'person': 0, 'user': 1, 'song': 2, pad_token: 3}\n",
    "relation_to_ix = {'song_person': 0, 'person_song': 1, 'user_song': \n",
    "                  2, 'song_user': 3, '#UNK_RELATION': 4, '#END_RELATION': 5, pad_token: 6}\n",
    "\n",
    "PERSON_TYPE = 0\n",
    "USER_TYPE = 1\n",
    "SONG_TYPE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct mappings from entity, type, and relation to idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entity vocab set is combination of songs, users, and persons\n",
    "#currently using dicts and not id_txt files since it seemed like there were missing songs\n",
    "with open('../song_data/dense_song_user_edges.dict', 'rb') as handle:\n",
    "    songs1 = set(pickle.load(handle).keys())\n",
    "    \n",
    "with open('../song_data/dense_song_person_edges.dict', 'rb') as handle:\n",
    "    songs2 = set(pickle.load(handle).keys())\n",
    "\n",
    "with open('../song_data/dense_user_song_edges.dict', 'rb') as handle:\n",
    "    users = set(pickle.load(handle).keys())\n",
    "    \n",
    "with open('../song_data/dense_person_song_edges.dict', 'rb') as handle:\n",
    "    persons = set(pickle.load(handle).keys())\n",
    "\n",
    "songs = songs1|songs2\n",
    "entities = songs|users|persons\n",
    "\n",
    "#if we have singe map for all entities need to ensure no duplicates across categories\n",
    "#assert len(entities) == len(songs) + len(persons) + len(users)\n",
    "\n",
    "song_to_ix = {(song, SONG_TYPE): idx for idx, song in enumerate(songs)}\n",
    "user_to_ix = {(user, USER_TYPE): idx+len(song_to_ix) for idx, user in enumerate(users)}\n",
    "person_to_ix = {(person, PERSON_TYPE): idx+len(song_to_ix)+len(user_to_ix) for idx, person in enumerate(persons)}\n",
    "\n",
    "entity_to_ix = {(song, SONG_TYPE): idx for idx, song in enumerate(songs)}\n",
    "entity_to_ix.update({(user, USER_TYPE): idx+len(song_to_ix) for idx, user in enumerate(users)})\n",
    "entity_to_ix.update({(person, PERSON_TYPE): idx+len(song_to_ix)+len(user_to_ix) for idx, person in enumerate(persons)})\n",
    "# entity_to_ix = {entity: idx for idx, entity in enumerate(entities)}\n",
    "entity_to_ix[pad_token] = len(entity_to_ix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('j5LGMfs4plGaq/D5+SL0LMjacBoUqalCy0EMgFcgMlc=', 2), 0), (('tjEAVmOfXQ8WMdYIrZS+R0g1pqIkAVDyNJopcS2JYb0=', 2), 1), (('YYE8FWKKw4SUWh5D6MT5scCzqzM1A06xu4cn5PS5Qmk=', 2), 2), (('rjGMmJQdMqSXYsBQqBIep5R6/EuSqOOw7esglyYTMvY=', 2), 3), (('Sn58k5eJwU+7S2ly9zh6Y76ij/+XRuO8qKPNoSNUQxg=', 2), 4), (('kRMRCgV7KrL58jWquyAWnG86og5OvdJPZm8QjzcMQbg=', 2), 5), (('h6skjx9MLDncJbnJO78z+1BNMlNb4lbHFwB3bb3IIXo=', 2), 6), (('KiMWEQZ8bRK2muIqMco7D+InjtRjhq0snyWZUzVtgq0=', 2), 7), (('LI7fY0r1sF1vWupMTikBOf1XVvdzGuEpO4z/25mR4sM=', 2), 8), (('N1FzNcXRVM56iEVz4ebZqXOjMdq5SKh+fDiCHCCVT3E=', 2), 9)]\n",
      "[(('8ObZ/AgRUoSDPNFXyJI+0ZFiiIbIkF071v3pblsq15Y=', 1), 224214), (('WtuOpsYQ8St9zt7yySdryqDUCxeT4/v2rLRA7+lsahQ=', 1), 224215), (('QI93Z+LZKpTMf9FiVRH6ofB8mM1niwlqP4SOIi11Nyo=', 1), 224216), (('Pd6ojPIwyQr9kVrW0//vMGDYVs+BIyUaLBY1SkcM6dM=', 1), 224217), (('jbV+lsBsMOOrGuh7x3jME4IsgVa1ia0ousrp2xeKCF4=', 1), 224218), (('jngE9C59J4eDq9zTJA/xjsXZceghW7Mb2g1RHFHtNFY=', 1), 224219), (('PwNcK9pmv+Z246XF98nPW9ID/9xvqEzCh6IG/a7RPZg=', 1), 224220), (('3eGr/4kbHXSbEUZdO5MrkIdZRZ3ikSZnoZGW5x6t6Zk=', 1), 224221), (('hZHtPRdO0B5GIPfsjoiBs/FL7idyYrsqJ5HTbFeCj7Y=', 1), 224222), (('P91w/h5+ETY2ScpJccDfR2+pe+lTaMk7nD89xWMAS5Y=', 1), 224223)]\n",
      "[(('', 0), 227330), (('Dorothy Martin', 0), 227331), (('Laila Samulesen', 0), 227332), (('D.Barnett', 0), 227333), (('Taylor Dayne', 0), 227334), (('Anggun', 0), 227335), (('Don Mescall', 0), 227336), (('Jose Carreras', 0), 227337), (('S. Jefroy', 0), 227338), (('Dan Penn', 0), 227339)]\n",
      "262654\n"
     ]
    }
   ],
   "source": [
    "print(list(song_to_ix.items())[:10])\n",
    "print(list(user_to_ix.items())[:10])\n",
    "print(list(person_to_ix.items())[:10])\n",
    "print(len(entity_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262653\n",
      "262654\n"
     ]
    }
   ],
   "source": [
    "print(len(songs) + len(persons) + len(users))\n",
    "print(len(entity_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in entities)\n",
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in persons)\n",
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in users)\n",
    "print('6uYPDXZJGYhq6WDg35xDLMB0Z46Rw3Y0XTLik5F/w9c=' in songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct inverse idx mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_type = {v: k for k, v in type_to_ix.items()}\n",
    "ix_to_relation = {v: k for k, v in relation_to_ix.items()}\n",
    "ix_to_entity = {v: k for k, v in entity_to_ix.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save idx mappings as .dict files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('type_to_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(type_to_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('relation_to_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(relation_to_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('entity_to_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(entity_to_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('ix_to_type.dict', 'wb') as handle:\n",
    "    pickle.dump(ix_to_type, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('ix_to_relation.dict', 'wb') as handle:\n",
    "    pickle.dump(ix_to_relation, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('ix_to_entity.dict', 'wb') as handle:\n",
    "    pickle.dump(ix_to_entity, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Construct relation and type dictionaries replacing names with ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ids(rel_dict, start_type, end_type):\n",
    "    new_rel = {}\n",
    "    for key,values in rel_dict.items():\n",
    "        key_id = entity_to_ix[(key, start_type)]\n",
    "        value_ids = []\n",
    "        for val in values:\n",
    "            value_ids.append(entity_to_ix[(val, end_type)])\n",
    "        new_rel[key_id] = value_ids\n",
    "    \n",
    "    return new_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)\n",
    "with open('../song_data/dense_song_user_edges.dict', 'rb') as handle:\n",
    "    song_user = pickle.load(handle)\n",
    "    song_user_ix = convert_to_ids(song_user, SONG_TYPE, USER_TYPE)\n",
    "\n",
    "print(1)\n",
    "with open('../song_data/dense_user_song_edges.dict', 'rb') as handle:\n",
    "    user_song = pickle.load(handle)\n",
    "    user_song_ix = convert_to_ids(user_song, USER_TYPE, SONG_TYPE)\n",
    "\n",
    "print(1)\n",
    "with open('../song_data/dense_song_person_edges.dict', 'rb') as handle:\n",
    "    song_person = pickle.load(handle)\n",
    "    song_person_ix = convert_to_ids(song_person, SONG_TYPE, PERSON_TYPE)\n",
    "\n",
    "print(1)\n",
    "with open('../song_data/dense_person_song_edges.dict', 'rb') as handle:\n",
    "    person_song = pickle.load(handle)\n",
    "    person_song_ix = convert_to_ids(person_song, PERSON_TYPE, SONG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'a0S959XXxdHq02RRyJIYYysamjxwJNmoCnkadrWVrjA='",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-286612ddcf73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mentity_ix_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mkey_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity_to_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mentity_ix_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'a0S959XXxdHq02RRyJIYYysamjxwJNmoCnkadrWVrjA='"
     ]
    }
   ],
   "source": [
    "#Convert entity to id dict to entity_ix to id dict\n",
    "with open('../song_data/id_type.dict', 'rb') as handle:\n",
    "    entity_type = pickle.load(handle)\n",
    "    entity_ix_type = {}\n",
    "    for key in entities:\n",
    "        value = entity_type[key]\n",
    "        key_id = entity_to_ix[(key, int(value))]    \n",
    "        entity_ix_type[key_id] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('song_user_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(song_user_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(user_song_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('song_person_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(song_person_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('person_song_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(person_song_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('entity_ix_type.dict', 'wb') as handle:\n",
    "    pickle.dump(entity_ix_type, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert training test pos neg dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../song_data/song_user_train_dense.dict', 'rb') as handle:\n",
    "    song_user_train = pickle.load(handle)\n",
    "    song_user_train_ix = convert_to_ids(song_user_train, SONG_TYPE, USER_TYPE)\n",
    "with open('../song_data/song_user_test_dense.dict', 'rb') as handle:\n",
    "    song_user_test = pickle.load(handle)\n",
    "    song_user_test_ix = convert_to_ids(song_user_test, SONG_TYPE, USER_TYPE)\n",
    "with open('../song_data/user_song_train_dense.dict', 'rb') as handle:\n",
    "    user_song_train = pickle.load(handle)\n",
    "    user_song_train_ix = convert_to_ids(user_song, USER_TYPE, SONG_TYPE)\n",
    "with open('../song_data/user_song_test_dense.dict', 'rb') as handle:\n",
    "    user_song_test = pickle.load(handle)\n",
    "    user_song_test_ix = convert_to_ids(user_song_test, USER_TYPE, SONG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('song_user_train_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(song_user_train_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('song_user_test_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(song_user_test_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_train_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(user_song_train_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_test_ix.dict', 'wb') as handle:\n",
    "    pickle.dump(user_song_test_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ids_tuples(tuples, start_type, end_type):\n",
    "    new_tuples = []\n",
    "    for user,song in tuples:\n",
    "        user_id = entity_to_ix[(user, start_type)]\n",
    "        song_id = entity_to_ix[(song, end_type)]\n",
    "        new_tuples.append((user_id, song_id))\n",
    "        \n",
    "    return new_tuples\n",
    "\n",
    "with open('../song_data/user_song_tuple_train_pos_dense.txt', 'rb') as handle:\n",
    "    user_song_tuple_train_pos = pickle.load(handle)\n",
    "    user_song_tuple_train_pos_ix = convert_to_ids_tuples(user_song_tuple_train_pos, USER_TYPE, SONG_TYPE)\n",
    "with open('../song_data/user_song_tuple_test_pos_dense.txt', 'rb') as handle:\n",
    "    user_song_tuple_test_pos = pickle.load(handle)\n",
    "    user_song_tuple_test_pos_ix = convert_to_ids_tuples(user_song_tuple_test_pos, USER_TYPE, SONG_TYPE)\n",
    "with open('../song_data/user_song_tuple_train_neg_dense.txt', 'rb') as handle:\n",
    "    user_song_tuple_train_neg = pickle.load(handle)\n",
    "    user_song_tuple_train_neg_ix = convert_to_ids_tuples(user_song_tuple_train_neg, USER_TYPE, SONG_TYPE)\n",
    "with open('../song_data/user_song_tuple_test_neg_dense.txt', 'rb') as handle:\n",
    "    user_song_tuple_test_neg = pickle.load(handle)\n",
    "    user_song_tuple_test_neg_ix = convert_to_ids_tuples(user_song_tuple_test_neg, USER_TYPE, SONG_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('user_song_tuple_train_pos_ix.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple_train_pos_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_tuple_train_neg_ix.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple_train_neg_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_tuple_test_pos_ix.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple_test_pos_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('user_song_tuple_test_neg_ix.txt', 'wb') as handle:\n",
    "    pickle.dump(user_song_tuple_test_neg_ix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
